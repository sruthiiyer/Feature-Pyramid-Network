{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FPN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4sZmaJgdbkF",
        "colab_type": "text"
      },
      "source": [
        "# **FEATURE PYRAMID NETWORK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqAh1CeR3dl-",
        "colab_type": "text"
      },
      "source": [
        "Importing the rquired libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAC_w7RZ8YDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge7SnWJX3zE0",
        "colab_type": "text"
      },
      "source": [
        "Class FPN  gives multiple feature maps for "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaRgb9dT8Es_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FPN(nn.Module):\n",
        "    def __init__(self,C3_size = 128, C4_size = 256, C5_size = 512,feature_size=256):\n",
        "        super().__init__()\n",
        "\n",
        "        # upsample C5 to get P5 from the FPN paper\n",
        "        self.P5_1 = nn.Conv2d(C5_size,feature_size,1)\n",
        "        self.P5_upsampled = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.P5_2 = nn.Conv2d(feature_size,feature_size,3,1,1)\n",
        "\n",
        "        # add P5 elementwise to C4        \n",
        "        self.P4_1 = nn.Conv2d(C4_size,feature_size,1)\n",
        "        self.P4_upsampled = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.P4_2 = nn.Conv2d(feature_size,feature_size,3,1,1)\n",
        "        \n",
        "        # add P4 elementwise to C3\n",
        "        self.P3_1 = nn.Conv2d(C3_size,feature_size,1)\n",
        "        self.P3_2 = nn.Conv2d(feature_size,feature_size,3,1,1)\n",
        "\n",
        "        # \"P6 is obtained via a 3x3 stride-2 conv on C5\"       \n",
        "        self.P6 = nn.Conv2d(512, feature_size, kernel_size=3, stride=2, padding=1)\n",
        "        \n",
        "        # \"P7 is computed by applying ReLU followed by a 3x3 stride-2 conv on P6\"\n",
        "        self.P7_1 = nn.ReLU()\n",
        "        self.P7_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=2, padding=1)\n",
        " #       self.apply(initialize_layer)\n",
        "        \n",
        "        \n",
        "    def forward(self,C3,C4,C5):\n",
        "  #      print(C3,\"\\n\",C4,\"\\n\",C5)\n",
        "        P5_x = self.P5_1(C5)\n",
        "        P5_upsampled_x = self.P5_upsampled(P5_x)\n",
        "        P5_x = self.P5_2(P5_x)\n",
        "        \n",
        "        P4_x = self.P4_1(C4)\n",
        "        P4_x = P5_upsampled_x + P4_x\n",
        "        P4_upsampled_x = self.P4_upsampled(P4_x)\n",
        "        P4_x = self.P4_2(P4_x)\n",
        "        \n",
        "        P3_x = self.P3_1(C3)\n",
        "        P3_x = P3_x + P4_upsampled_x\n",
        "        P3_x = self.P3_2(P3_x)\n",
        "        \n",
        "        P6_x = self.P6(C5)\n",
        "        \n",
        "        P7_x = self.P7_1(P6_x)\n",
        "        P7_x = self.P7_2(P7_x)\n",
        "\n",
        "        \n",
        "        return [P3_x,P4_x,P5_x,P6_x,P7_x]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYCOFMc14Qwd",
        "colab_type": "text"
      },
      "source": [
        "Class Resnet is defined for creating model with 4 convolution blocks and 4 residual layers(Basic Block). The convolution block down-samples the input and residual layer improves the model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO7G001B8EBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        resnet = models.resnet34(pretrained=True)\n",
        "        resnet = list(resnet.children())\n",
        "        self.conv_block = nn.Sequential(*resnet[:4])\n",
        "        self.res_layers = nn.ModuleList(resnet[4:8])\n",
        "    def forward(self,x):\n",
        "       # print(self.conv_block(x))\n",
        "        x = self.conv_block(x)\n",
        "        layer_features = []\n",
        "        for layer in self.res_layers:\n",
        "            x = layer(x)\n",
        "            layer_features.append(x)\n",
        "        return layer_features[1:]\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE5j9tsV8JZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet = ResNet()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw4H6zel3qO_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb4b995a-3f87-4627-f69e-2b434cbeb3d6"
      },
      "source": [
        "resnet"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv_block): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (res_layers): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (5): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJE70ZLi9gp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fpn = FPN()\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1tRJEDZ7LQC",
        "colab_type": "text"
      },
      "source": [
        "Input shape: 2 batches, 3 channels, 256 height, 256 width "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdokYM6Q9EDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.randn([2,3,256,256])\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE0Ud1Cj9Xht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f041e5e-a596-4cf0-f469-8ef7361e2c8a"
      },
      "source": [
        "c3,c4,c5 = resnet(x)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[1.0743, 0.6214, 0.8941,  ..., 0.7211, 0.4373, 0.6657],\n",
            "          [1.0743, 0.7889, 0.7313,  ..., 0.7211, 0.9878, 0.9878],\n",
            "          [1.0010, 0.7889, 0.8432,  ..., 0.9725, 0.9878, 0.9878],\n",
            "          ...,\n",
            "          [0.5704, 0.9695, 0.7770,  ..., 0.8019, 0.9754, 0.9754],\n",
            "          [0.6930, 0.9695, 1.1037,  ..., 0.9050, 0.9050, 0.6373],\n",
            "          [0.6563, 0.9083, 1.1037,  ..., 0.9050, 0.9643, 0.7323]],\n",
            "\n",
            "         [[0.4413, 0.2925, 0.4300,  ..., 0.4512, 0.3490, 0.2707],\n",
            "          [0.6643, 0.6643, 0.3898,  ..., 0.6287, 0.6246, 0.5311],\n",
            "          [0.6643, 0.6643, 0.4486,  ..., 0.5682, 0.6246, 0.8432],\n",
            "          ...,\n",
            "          [0.5025, 0.5784, 0.5784,  ..., 0.5519, 0.4680, 0.2235],\n",
            "          [0.3164, 0.5784, 0.5784,  ..., 0.7225, 0.7225, 0.1824],\n",
            "          [0.9370, 0.9370, 0.6040,  ..., 0.4846, 0.3545, 0.5783]],\n",
            "\n",
            "         [[0.4841, 0.7092, 0.6063,  ..., 0.6074, 0.6077, 0.4752],\n",
            "          [0.7080, 0.9971, 0.9971,  ..., 0.6300, 0.8929, 0.4752],\n",
            "          [0.7152, 0.8112, 0.3825,  ..., 0.6300, 0.8929, 0.5772],\n",
            "          ...,\n",
            "          [0.7216, 0.6779, 0.5931,  ..., 0.7016, 0.6182, 0.6182],\n",
            "          [0.7216, 0.7506, 0.9383,  ..., 1.2366, 1.0713, 0.6345],\n",
            "          [0.4367, 0.5673, 1.0063,  ..., 1.0713, 1.0713, 0.6345]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.4631, 0.5136, 0.5667,  ..., 0.5432, 0.5431, 0.4030],\n",
            "          [0.4712, 0.4097, 0.4994,  ..., 0.5628, 0.6433, 0.6433],\n",
            "          [0.5353, 0.5353, 0.4994,  ..., 0.5578, 0.6433, 0.7442],\n",
            "          ...,\n",
            "          [0.4989, 0.4992, 0.6277,  ..., 0.4724, 0.8352, 0.7492],\n",
            "          [0.5269, 0.5269, 0.6277,  ..., 0.5113, 0.8352, 0.4323],\n",
            "          [0.7314, 0.7314, 0.6150,  ..., 0.6065, 0.5113, 0.5433]],\n",
            "\n",
            "         [[0.8401, 1.2824, 1.2824,  ..., 1.0850, 1.0700, 1.0700],\n",
            "          [1.1621, 1.2824, 1.2824,  ..., 0.9229, 0.9318, 0.9318],\n",
            "          [0.9411, 0.8724, 0.6991,  ..., 0.9261, 1.3514, 1.3058],\n",
            "          ...,\n",
            "          [1.4014, 1.1527, 1.1284,  ..., 1.2539, 1.3597, 0.8719],\n",
            "          [0.6445, 1.3762, 1.0050,  ..., 1.2539, 1.3847, 1.3847],\n",
            "          [0.7149, 1.3762, 1.5985,  ..., 0.9044, 1.3847, 1.3847]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.8690, 0.9500, 0.6778,  ..., 0.6844, 0.6844, 0.6101],\n",
            "          [0.8690, 0.9500, 0.6141,  ..., 1.1189, 1.1189, 0.8623],\n",
            "          [1.0288, 0.8124, 0.7426,  ..., 1.0381, 0.6853, 0.6192],\n",
            "          ...,\n",
            "          [0.9795, 0.9795, 1.0115,  ..., 1.1368, 1.0994, 1.0994],\n",
            "          [0.9874, 0.9874, 0.9009,  ..., 1.1368, 0.8269, 0.7147],\n",
            "          [1.0666, 1.0492, 1.0492,  ..., 0.9731, 0.9731, 0.8125]],\n",
            "\n",
            "         [[0.0668, 0.5043, 0.2697,  ..., 0.5512, 0.2665, 0.6936],\n",
            "          [0.2109, 0.5043, 0.3736,  ..., 0.8506, 0.2428, 0.7392],\n",
            "          [0.5009, 0.0645, 0.4165,  ..., 0.7499, 0.7499, 0.7392],\n",
            "          ...,\n",
            "          [0.4064, 0.5135, 0.7998,  ..., 0.6278, 0.5316, 0.4416],\n",
            "          [0.5831, 0.5831, 0.7435,  ..., 0.6940, 0.5316, 0.5163],\n",
            "          [0.8305, 0.8305, 0.5009,  ..., 0.5578, 0.4618, 0.4313]],\n",
            "\n",
            "         [[0.5514, 0.4069, 0.5432,  ..., 0.7389, 0.6096, 0.6096],\n",
            "          [0.6363, 0.6363, 0.7237,  ..., 0.4633, 0.6096, 0.6096],\n",
            "          [0.5080, 0.7916, 0.8183,  ..., 0.4633, 0.8543, 0.8543],\n",
            "          ...,\n",
            "          [0.7620, 0.7620, 0.9764,  ..., 0.8542, 0.9340, 0.9340],\n",
            "          [0.7620, 0.7620, 0.8112,  ..., 0.6563, 0.6563, 0.6391],\n",
            "          [0.6758, 0.7568, 0.8112,  ..., 0.6563, 0.6563, 0.5594]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.3369, 0.3369, 0.3166,  ..., 0.4204, 0.4565, 0.5920],\n",
            "          [0.3864, 0.4094, 0.5500,  ..., 0.5242, 0.4223, 0.7518],\n",
            "          [0.4136, 0.4559, 0.5609,  ..., 0.4795, 0.5138, 0.7518],\n",
            "          ...,\n",
            "          [0.4792, 0.4944, 0.4125,  ..., 0.6894, 0.6894, 0.5307],\n",
            "          [0.5856, 0.5856, 0.5314,  ..., 0.6888, 0.5062, 0.5703],\n",
            "          [0.6332, 0.6435, 0.6435,  ..., 0.5653, 0.5653, 0.5685]],\n",
            "\n",
            "         [[1.1684, 0.9188, 0.9338,  ..., 1.0298, 0.8937, 0.8203],\n",
            "          [1.2578, 1.2578, 1.0446,  ..., 0.8863, 1.0585, 1.0585],\n",
            "          [1.2578, 1.2578, 1.0845,  ..., 1.2077, 1.0643, 1.0585],\n",
            "          ...,\n",
            "          [0.9760, 1.1183, 0.9585,  ..., 0.8885, 1.0492, 1.2235],\n",
            "          [1.1523, 1.1523, 1.0321,  ..., 1.6734, 1.6734, 1.2235],\n",
            "          [1.1523, 1.1523, 0.9434,  ..., 1.2417, 1.2417, 0.7151]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
            "       grad_fn=<MaxPool2DWithIndicesBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW1V2USn9Z3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = fpn(c3,c4,c5)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEpmNRTL7a0H",
        "colab_type": "text"
      },
      "source": [
        "The feature map size gets doubled as we upsample the features by a factor of 2 from the top of the pyramid.\n",
        "If P5, P4, P3, P2 are the feature maps, P5 < P4 < P3 < based on their size "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlVILgWe9x-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "9f9752a1-c1f8-4868-8247-c55df20f5201"
      },
      "source": [
        "for f in features:\n",
        "    print(f.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 256, 32, 32])\n",
            "torch.Size([2, 256, 16, 16])\n",
            "torch.Size([2, 256, 8, 8])\n",
            "torch.Size([2, 256, 4, 4])\n",
            "torch.Size([2, 256, 2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}